{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reaction Bench: Lesson 1\n",
    "\n",
    "### Part 1:\n",
    "\n",
    "In this lesson I will be taking you through how our reaction bench environment works and how an RL agent might interact with the environment.\n",
    "\n",
    "The reaction bench environment is meant to as it sounds simulate a reaction, in most reaction benches the agent will have a number of reagents and the ability to play with the environmental conditions of the reaction and through doing this the agent is trying to maximize the yield of a certain desired material. For the reaction bench we use a reaction file which specifies the mechanics of a certain reaction or multiple reactions. For instance the Wurtz reaction is made up of 6 different reactions and as such is a very complicated reaction which the agent has to try and learn the mechanisms of the reaction environment it is in. For this lesson we will be using a simplified version of the wurtz reaction to introduce you to how actions affect the environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is just some simple code that loads our desired environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../chemistrylab/reactions')\n",
    "import gym\n",
    "import chemistrylab\n",
    "import numpy as np\n",
    "from gym import envs\n",
    "all_envs = envs.registry.all()\n",
    "env_ids = [env_spec.id for env_spec in all_envs if 'React' in env_spec.id]\n",
    "print(env_ids)\n",
    "env = gym.make('WurtzReact-v1')\n",
    "render_mode = \"human\"\n",
    "action_set = ['Temperature', 'Volume', \"1-chlorohexane\", \"2-chlorohexane\", \"3-chlorohexane\", \"Na\"]\n",
    "\n",
    "assert len(action_set) == env.action_space.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firtst let's load up the environment, I highly recommend you look at the source code for the reaction bench and\n",
    "reaction, it should help provide insight into how this all works. Further the lesson on creating a custom reaction\n",
    "environment will also help give insight into the reaction mechanics. If you run the cell below you will see a graph appear that looks something like this:\n",
    "\n",
    "![graph](sample_figures/tutorial/wurtz_overlap_0.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "env.reset()\n",
    "env.render(mode=render_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding the graph above is important to understanding how the agent will have to understand the environment.\n",
    "On the left we can see the absorbance spectra of the materials in our reaction vessel, and on the right we have\n",
    "a relative scale of a number of important metrics. From left to right we have time passed, temperature, volume (solvent)\n",
    ", presure, and the quantity of reagents that we have available to use. All of this data is what the RL agent has inorder\n",
    "for it to try and optimize the reaction pathway. \n",
    "\n",
    "The reaction we are using is as follows:\n",
    "\n",
    "2 1-chlorohexane + 2 Na --> dodecane + 2 NaCl\n",
    "\n",
    "This reaction is performed in an aqueous state with ethoxyethane as the solvent.\n",
    "\n",
    "With all that out of the way let's focus our attention to the action space. For this reaction environemnt our action\n",
    "space is represented by a 6 element vector. \n",
    "\n",
    "|              | Temperature | Volume | 1-chlorohexane | 2-chlorohexane | 3-chlorohexane | Na  |\n",
    "|--------------|-------------|--------|----------------|----------------|----------------|-----|\n",
    "| Value range: | 0-1         | 0-1    | 0-1            | 0-1            | 0-1            | 0-1 |\n",
    "\n",
    "As you might have noticed now, the reaction bench environment deals with a continuous action space. So what exactly do\n",
    "these continuous values represent? For the environmental conditions, in this case Volume and Temperature 0 represents a\n",
    "decrease in temperature  or volume by dT or dV (specified in the reaction bench), 1/2 represents no change, and\n",
    "1 represents an increase by dT or dV. For the chemicals, 0 represents adding no amount of that chemical to the reaction\n",
    "vessel, and 1 represents adding all of the originally available chemical (there is a negative reward if you try to add\n",
    "more chemical than is available). \n",
    "\n",
    "Below you will find a code cell that will allow you to interact with the gym environment, I highly encourage you to play around with different actions and to not the rewards as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "done = False\n",
    "state = env.reset()\n",
    "total_reward = 0\n",
    "while not done:\n",
    "    # print(state)\n",
    "    env.render(mode=render_mode)\n",
    "    action = np.zeros(env.action_space.shape[0])\n",
    "    print('--------------------')\n",
    "    for i, a in enumerate(action_set):\n",
    "        action[i] = float(input(f'{a}: '))\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    total_reward += reward\n",
    "    print(f'reward: {reward}')\n",
    "    print(f'total_reward: {total_reward}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2:\n",
    "\n",
    "\n",
    "Here I will provide instructions on how to maximize the return of this reaction environment.\n",
    "\n",
    "This is fairly simple for this task and have thus provided some script which demonstrates our strategy, and I encourage\n",
    "you to try your own strategy and see how it performs. In this case cour strategy is at step 1 to increase the temperature,\n",
    "keep the volume of solvent constant, and to add all our reagents, in this case 1-chlorohexane and Na. This gives us an\n",
    "action vector of:\n",
    "\n",
    "| Temperature | Volume | 1-chlorohexane | 2-chlorohexane | 3-chlorohexane | Na  |\n",
    "|-------------|--------|----------------|----------------|----------------|-----|\n",
    "| 1         | 1/2    | 1            | 0            | 0            | 1 |\n",
    "\n",
    "![image of reaction](https://image1.masterfile.com/getImage/NjQwLTAzMjU4NDA1ZW4uMDAwMDAwMDA=ANb9FF/640-03258405en_Masterfile.jpg)\n",
    "\n",
    "Then at every next step we are going to keep the solvent volume constant and increase the temperature\n",
    "\n",
    "| Temperature | Volume | 1-chlorohexane | 2-chlorohexane | 3-chlorohexane | Na  |\n",
    "|-------------|--------|----------------|----------------|----------------|-----|\n",
    "| 1         | 1/2    | 0            | 0            | 0            | 0 |\n",
    "\n",
    "![heating up vessel](https://media.sciencephoto.com/image/c0150431/800wm)\n",
    "\n",
    "To see this in action simply run the following code cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "done = False\n",
    "state = env.reset()\n",
    "total_reward = 0\n",
    "round = 0\n",
    "\n",
    "while not done:\n",
    "    # print(state)\n",
    "    env.render(mode=render_mode)\n",
    "    action = np.zeros(env.action_space.shape[0])\n",
    "    if round == 0:\n",
    "        action[0] = 1\n",
    "        action[1] = 1\n",
    "        action[2] = 1\n",
    "        action[-1] = 1\n",
    "    else:\n",
    "        action[0] = 1\n",
    "        action[1] = 1\n",
    "\n",
    "    print('--------------------')\n",
    "    print(round)\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    total_reward += reward\n",
    "    print(f'reward: {reward}')\n",
    "    print(f'total_reward: {total_reward}')\n",
    "    round += 1\n",
    "    if done:\n",
    "        wait = input(\"PRESS ENTER TO EXIT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're done! I hope you have a better sense of how the reaction environment works and the process through which\n",
    "an RL agent must go through to learn the environment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
