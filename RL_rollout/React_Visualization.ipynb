{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211635e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from RLTrain import Opt\n",
    "import os\n",
    "import time\n",
    "#print(Opt())\n",
    "import pandas as pd\n",
    "from RadarGraph import *\n",
    "#plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.rcParams[\"font.size\"]=14.0\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from visualization_helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b905fdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotabt(all_acts,actions,colors,labels,points,names,title_ext=\"\",title=None,ylim=(-0.15,1.15)):\n",
    "    \"\"\"Plotting Function for actions vs time\n",
    "    Inputs:\n",
    "        all_act (list<np.array>) -- shape is [number of models, number of timesteps, number of actions]\n",
    "        actions (list<str>) -- list of the name of each action\n",
    "        colors (list<str>) -- list of colors (should be at least as long as the number of models)\n",
    "        names (list<str>) -- the names of each model\n",
    "        title_ext (str) -- addition you want to add to the end of the graph title\n",
    "    \n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(figsize=(12, 6), nrows=len(actions), ncols=len(all_acts[0]))\n",
    "    fig.subplots_adjust(wspace=0.0, hspace=0.0, top=0.85, bottom=0.05)\n",
    "    for i,ax0 in enumerate(axs):\n",
    "        for k,all_act in enumerate(all_acts):\n",
    "            for j,act in enumerate(all_act):\n",
    "                axs[0][j].set_title(names[j])\n",
    "                ax=ax0[j]\n",
    "                ax.plot(act[:,i],points[k],color=colors[k],ms=3,alpha=0.5,label=labels[k])\n",
    "                ax.set_ylim(*ylim)\n",
    "                if j!=0:\n",
    "                    ax.set_yticks([])\n",
    "                    #ax.set_yticks([int(a) for a in ylim])\n",
    "        \n",
    "        ax.text(act.shape[0],ylim[1]*0.5,actions[i],horizontalalignment=\"right\",verticalalignment=\"top\"\n",
    "                ,bbox=dict(boxstyle=\"square\",facecolor=\"w\",edgecolor=\"k\",alpha=0.8))\n",
    "    ax.legend()\n",
    "    if title is None:\n",
    "        axs[0][(int(len(names)-0.5)//2)-1].text(2,2,\"Average Value of Each Action vs Step %s\"%title_ext)\n",
    "    else:\n",
    "        axs[0][(int(len(names)-0.5)//2)-1].text(2,2,title)\n",
    "    #axs[0,-1].legend(names,loc=(0.8, .0))\n",
    "    axs[-1,0].set_xlabel(\"Step\")\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8777f94f",
   "metadata": {},
   "source": [
    "# Wurtz React"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab37a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = \"MODELS\\\\GenWurtzReact-v1\"\n",
    "\n",
    "obj = lambda x: get_conditional_rewards(x,CWtargs)[1].mean()\n",
    "\n",
    "folders,objectives = load_rollouts(parent_dir,obj=obj,last=False)\n",
    "\n",
    "if \"Heuristic\" in folders:\n",
    "    gheuristic=folders[\"Heuristic\"]\n",
    "    del folders[\"Heuristic\"]\n",
    "else:\n",
    "    gheuristic = pd.read_pickle(\"MODELS\\\\GenWurtzReact-v1\\\\Heuristic/rollout\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bc586a",
   "metadata": {},
   "source": [
    "## Returns during Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fe66eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1,figsize=(8,6), dpi=240, facecolor='w', edgecolor='k')\n",
    "\n",
    "colors = [\"r\",\"g\",\"m\",\"b\",\"y\",\"c\",\"k\"]\n",
    "points = ['s', '+', 'x', '.','p',\"*\",\"D\"]\n",
    "\n",
    "for i,algo in enumerate(folders):\n",
    "    subf = parent_dir+\"\\\\\"+algo\n",
    "    returns,counts=merge_varying_graphs(subf,steps=20,separate_runs=False)    \n",
    "    #Average over the different runs\n",
    "    mean,stdv,steps,n= mean_stdv_step_n(returns,interp_steps=32)\n",
    "    \n",
    "    plt.plot(steps,mean,\"-\",marker=points[i],color=colors[i],label=algo,ms=3,lw=0.5)\n",
    "    plt.fill_between(steps,mean-stdv/5,mean+stdv/5,color=colors[i],alpha=0.4,lw=0)\n",
    "    \n",
    "plt.xlim(steps[0],np.ceil(steps[-1]/1e3)*1e3)\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Return\")\n",
    "plt.legend(loc=\"lower right\")    \n",
    "plt.savefig(\"Figures/React/GenWurtzReactRuns.pdf\",bbox_inches='tight')\n",
    "plt.title(\"GenWurtzReact-v1 Average Return vs Sequential Step \\n (10 envs in used in parallel, average over 10 runs)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c87a7f",
   "metadata": {},
   "source": [
    "## Returns VS Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69f0b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "heuristic_rewards=get_conditional_rewards(gheuristic)[1]\n",
    "radar_info={a:[get_conditional_rewards(folders[a])[1]/heuristic_rewards] for a in folders}\n",
    "\n",
    "\n",
    "radar_info[\"Heuristic\"] = [heuristic_rewards]\n",
    "\n",
    "fig,axs = stat_show(radar_info,CWtargs,[\"Return\"],figsize=(30,7))\n",
    "\n",
    "plt.savefig(\"Figures\\\\React\\\\Wurtz-best.pdf\",bbox_inches=\"tight\")\n",
    "\n",
    "#Add in a title\n",
    "fig.text(0.5, 0.8, \"Average Return VS Target Material (Best model trained with 0.5M Steps)\",\n",
    "             horizontalalignment='center', color='black', weight='bold',\n",
    "             size='large')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f724047",
   "metadata": {},
   "source": [
    "## Actions vs Timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046453ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_acts = []\n",
    "for i in range(7):\n",
    "    all_act = all_acts.append(([\n",
    "    actions_by_time(target_subset(folders[name],len(CWtargs),i)) for name in folders]\n",
    "    +[actions_by_time(target_subset(gheuristic,len(CWtargs),i))]))\n",
    "\n",
    "colors = [\"r\",\"g\",\"b\",\"c\",\"y\",\"m\",\"k\"]\n",
    "points = ['s-', 'o-', '*-', '.-','x-',\".-\",\".-\"]\n",
    "labels = CWtargs\n",
    "\n",
    "names=[name for name in folders]+[\"Heuristic\"]\n",
    "\n",
    "plotabt(all_acts,[\"dT\",\"dV\"]+CWchoices,colors,labels,points,names)\n",
    "\n",
    "\n",
    "plt.savefig(\"Figures\\\\React\\\\Wurtz-Actions.pdf\",bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42b6088",
   "metadata": {},
   "source": [
    "# Fict React"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2686eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_v1=False\n",
    "version = (\"v1\" if is_v1 else \"v2\")\n",
    "\n",
    "if is_v1:\n",
    "    parent_dir = \"MODELS\\\\FictReact-v1\"\n",
    "    FRtargs=[\"E\",\"F\",\"G\",\"H\",\"I\"]\n",
    "    FRchoices = [\"A\", \"B\", \"C\", \"D\", \"F\", \"G\" ,\"H\"]\n",
    "else:\n",
    "    parent_dir = \"MODELS\\\\FictReact-v2\"\n",
    "    FRtargs=['E', 'F', 'G', 'I']\n",
    "    FRchoices = ['A', 'B', 'D', 'F', 'G']\n",
    "obj = lambda x: get_conditional_rewards(x,FRtargs)[1].mean()\n",
    "\n",
    "folders,objectives = load_rollouts(parent_dir,obj=obj,last=False,verbose=False)\n",
    "if \"Heuristic\" in folders:\n",
    "    fheuristic=folders[\"Heuristic\"]\n",
    "    del folders[\"Heuristic\"]\n",
    "else:\n",
    "    fheuristic = pd.read_pickle(f\"MODELS\\\\FictReact-{version}\\\\Heuristic\\\\rollout\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ffa2ac",
   "metadata": {},
   "source": [
    "## Returns during Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d349fe0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1,figsize=(8,6), dpi=240, facecolor='w', edgecolor='k')\n",
    "\n",
    "colors = [\"r\",\"g\",\"m\",\"b\",\"y\",\"c\",\"k\"]\n",
    "points = ['s', '+', 'x', '.','p',\"*\",\"D\"]\n",
    "\n",
    "for i,algo in enumerate(folders):\n",
    "    subf = parent_dir+\"\\\\\"+algo\n",
    "    returns,counts=merge_varying_graphs(subf,steps=20,separate_runs=False)    \n",
    "    #Average over the different runs\n",
    "    mean,stdv,steps,n= mean_stdv_step_n(returns,interp_steps=32)\n",
    "    \n",
    "    plt.plot(steps,mean,\"-\",marker=points[i],color=colors[i],label=algo,ms=3,lw=0.5)\n",
    "    plt.fill_between(steps,mean-stdv/5,mean+stdv/5,color=colors[i],alpha=0.4,lw=0)\n",
    "    #plt.plot(np.arange(returns.shape[0])*20,returns,\".\",label=algo,alpha=0.3,mew=0,ms=8)\n",
    "    \n",
    "plt.xlim(steps[0],np.ceil(steps[-1]/1e3)*1e3)\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Return\")\n",
    "plt.legend()    \n",
    "plt.savefig(f\"Figures/React/FictReact-{version}Runs.pdf\",bbox_inches='tight')\n",
    "plt.title(f\"FictReact-{version} Average Return vs Sequential Step \\n (10 envs in used in parallel, average over 10 runs)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1eef76",
   "metadata": {},
   "source": [
    "## Returns vs Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6375fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "heuristic_rewards=get_conditional_rewards(fheuristic,FRtargs)[1]\n",
    "radar_info={a:[get_conditional_rewards(folders[a],FRtargs)[1]/heuristic_rewards] for a in folders}\n",
    "\n",
    "radar_info[\"Heuristic\"] = [heuristic_rewards]\n",
    "\n",
    "fig,axs = stat_show(radar_info,FRtargs,[\"Return\"],figsize=(30,7),gridlines=[0.2,0.4,0.6,0.8,1.0],rmax=1.0)\n",
    "#Add in a title\n",
    "\n",
    "plt.savefig(f\"Figures\\\\React\\\\Fict-{version}-best.pdf\",bbox_inches=\"tight\")\n",
    "\n",
    "fig.text(0.5, 0.8, \"Average Return VS Target Material (Best model trained with 0.5M Steps)\",\n",
    "             horizontalalignment='center', color='black', weight='bold',\n",
    "             size='large')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c64d059",
   "metadata": {},
   "source": [
    "## Actions Vs Timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349c7e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_acts = []\n",
    "for i in range(len(FRtargs)):\n",
    "    all_act = all_acts.append(([\n",
    "    actions_by_time(target_subset(folders[name],len(FRtargs),i)) for name in folders]\n",
    "    +[actions_by_time(target_subset(fheuristic,len(FRtargs),i))]))\n",
    "\n",
    "colors = [\"r\",\"g\",\"b\",\"m\",\"c\"]\n",
    "labels = FRtargs\n",
    "points = ['s-', 'o-', '*-', '.-',\"^-\"]\n",
    "names=[name for name in folders]+[\"Heuristic\"]\n",
    "\n",
    "plotabt(all_acts,[\"dT\",\"dV\"]+FRchoices[:-2],colors,labels,points,names)\n",
    "\n",
    "plt.savefig(f\"Figures/React/FictReact-{version}-actions.pdf\",bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4890e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,(ax0,ax1) = plt.subplots(1,2,width_ratios=(3,1),figsize=(8,6), dpi=240, facecolor='w', edgecolor='k')\n",
    "\n",
    "colors = [\"r\",\"g\",\"m\",\"b\",\"y\",\"c\",\"k\"]\n",
    "points = ['s', '+', 'x', '.','p',\"*\",\"D\"]\n",
    "\n",
    "for i,algo in enumerate(folders):\n",
    "    subf = parent_dir+\"\\\\\"+algo\n",
    "    returns,counts=merge_varying_graphs(subf,steps=20,separate_runs=False)    \n",
    "    #Average over the different runs\n",
    "    mean,stdv,steps,n= mean_stdv_step_n(returns,interp_steps=32)\n",
    "    \n",
    "    ax0.plot(steps,mean,\"-\",marker=points[i],color=colors[i],label=algo,ms=3,lw=0.5)\n",
    "    ax0.fill_between(steps,mean-stdv/5,mean+stdv/5,color=colors[i],alpha=0.4,lw=0)\n",
    "    #plt.plot(np.arange(returns.shape[0])*20,returns,\".\",label=algo,alpha=0.3,mew=0,ms=8)\n",
    "    \n",
    "ax0.set_xlim(steps[0],np.ceil(steps[-1]/1e3)*1e3)\n",
    "ax0.set_xlabel(\"Step\")\n",
    "ax0.set_ylabel(\"Return\")\n",
    "ax0.legend()    \n",
    "#plt.savefig(\"Legacy/Figures/FictReact/FictReactRuns.pdf\",bbox_inches='tight')\n",
    "#plt.title(\"FictReact-v2 Average Return vs Sequential Step \\n (10 envs in used in parallel, average over 10 runs)\")\n",
    "\n",
    "\n",
    "names=[a for a in folders]\n",
    "fig = plt.figure(1,figsize=(2,2), dpi=240, facecolor='w', edgecolor='k')\n",
    "\n",
    "x=np.arange(10)+1\n",
    "for i in range(10):\n",
    "    \n",
    "    arr = [(sorted(objectives[alg])[i],j) for j,alg in enumerate(names)]\n",
    "    \n",
    "    for val,idx in sorted(arr,key=lambda x:-abs(x[0])):\n",
    "        #print(idx,end=\"|\")\n",
    "        if i==0:\n",
    "            ax1.bar(x[i],val,color=colors[idx],label=names[idx])\n",
    "        else:\n",
    "            ax1.bar(x[i],val,color=colors[idx])\n",
    "    #print(\" Iter:\",i)\n",
    "\n",
    "#plt.legend()\n",
    "ax1.set_xticks([])\n",
    "ax1.set_yticks([])\n",
    "#plt.ylabel(\"Best Return\")\n",
    "ax1.set_xlabel(\"Run (sorted)\")\n",
    "\n",
    "ax0.set_ylim(-0.05,0.85)\n",
    "ax1.set_ylim(-0.05,0.85)\n",
    "\n",
    "fig.tight_layout(pad=0.0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0145c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1864ec83",
   "metadata": {},
   "outputs": [],
   "source": [
    "[get_conditional_rewards(folders[\"PPO\"],FRtargs)[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ba7231",
   "metadata": {},
   "outputs": [],
   "source": [
    "heuristic_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d1b080",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
