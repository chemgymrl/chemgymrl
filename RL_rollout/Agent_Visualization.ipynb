{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c5bae2a",
   "metadata": {},
   "source": [
    "# Default training Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9a1f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from RLTrain import Opt\n",
    "import os\n",
    "import time\n",
    "print(Opt())\n",
    "import pandas as pd\n",
    "from RadarGraph import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb426d9c",
   "metadata": {},
   "source": [
    "# Training an agent with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de2a407",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=time.time()\n",
    "#os.system(\"python RLTrain.py steps=200000\")\n",
    "print(time.time()-t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9349c8c2",
   "metadata": {},
   "source": [
    "# Running inference with the trained models and saving [S,A,R,S] info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f26ab82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.system(\"python RLTest.py PPO_WurtzReact-v1 steps=500\")\n",
    "#os.system(\"python RLTest.py WRH algorithm=WRH steps=500\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abe69d2",
   "metadata": {},
   "source": [
    "# Gathering some Heuristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af4131d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ppo = pd.read_pickle(\"PPO_WurtzReact-v1/rollout\")\n",
    "heuristic = pd.read_pickle(\"WRH/rollout\")\n",
    "\n",
    "print(ppo.keys())\n",
    "\n",
    "info = [\n",
    "    ['dT', 'dV', '1-chlorohexane', '2-chlorohexane', '3-chlorohexane', 'Na' ],\n",
    "    ('PPO', [\n",
    "        [a for a in ppo.Action.mean()],\n",
    "        [ppo[ppo.Done==True].Reward.mean()]*6,\n",
    "        [1,0,0,0,0,0]]),\n",
    "    ('Heuristic', [\n",
    "        [a for a in heuristic.Action.mean()],\n",
    "        [heuristic[heuristic.Done==True].Reward.mean()]*6,\n",
    "        [1,0,0,0,0,0]]),\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e86e941",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(heuristic[heuristic.Done==True].Reward.mean())\n",
    "\n",
    "print(ppo[ppo.Done==True].Reward.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7675cb7c",
   "metadata": {},
   "source": [
    "# Plot as a Radar Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63302b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from RadarGraph import *\n",
    "\n",
    "\n",
    "theta = radar_factory(len(info[0]), frame='polygon')\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(9, 9), nrows=1, ncols=2,subplot_kw=dict(projection='radar'))\n",
    "fig.subplots_adjust(wspace=0.5, hspace=0.25, top=0.85, bottom=0.05)\n",
    "\n",
    "make_radar(theta,axs,info,colors = \"brk\")\n",
    "\n",
    "labels = ('Action Taken', 'Return', '1', 'Factor 4', 'Factor 5')\n",
    "legend = axs[0].legend(labels, loc=(0.9, .95),labelspacing=0.1, fontsize='small')\n",
    "\n",
    "\n",
    "fig.text(0.5, 0.7, \"Average value of each action and episodic return for a 500 step rollout (PPO trained for 200K steps)\",\n",
    "             horizontalalignment='center', color='black', weight='bold',\n",
    "             size='large')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa7669e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def actions_by_time(frame):\n",
    "    \"\"\"Gives the mean action at each timestep of your rollout dataframe\"\"\"\n",
    "    min_t,max_t = frame.Step.min(),frame.Step.max()\n",
    "    mean_act=[]\n",
    "    for t in range(min_t,max_t+1):\n",
    "        mean_act+=[frame.Action[frame.Step==t].mean()]\n",
    "    return np.array(mean_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad83f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotabt(all_act,actions,colors,names,title_ext=\"\"):\n",
    "    \"\"\"Plotting Function for actions vs time\n",
    "    Inputs:\n",
    "        all_act (list<np.array>) -- shape is [number of models, number of timesteps, number of actions]\n",
    "        actions (list<str>) -- list of the name of each action\n",
    "        colors (list<str>) -- list of colors (should be at least as long as the number of models)\n",
    "        names (list<str>) -- the names of each model\n",
    "        title_ext (str) -- addition you want to add to the end of the graph title\n",
    "    \n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(figsize=(9, 10), nrows=len(actions), ncols=1)\n",
    "    fig.subplots_adjust(wspace=0.5, hspace=0.0, top=0.85, bottom=0.05)\n",
    "    for i,ax in enumerate(axs):\n",
    "\n",
    "        for j,act in enumerate(all_act):\n",
    "            ax.plot(act[:,i],\".-\",color=colors[j],ms=3)\n",
    "        #ax.legend([actions[i]],loc=(0.75, .7))\n",
    "        ax.set_ylim(-0.1,1.1)\n",
    "        ax.text(act.shape[0]*1.0,0.96,actions[i],horizontalalignment=\"right\"\n",
    "                ,bbox=dict(boxstyle=\"square\",facecolor=\"w\",edgecolor=\"k\",alpha=0.8))\n",
    "        if ax!= axs[-1]:\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([0,1])\n",
    "    axs[0].set_title(\"Average Value of Each Action vs Step %s\"%title_ext)\n",
    "    axs[0].legend(names,loc=(0.8, .0))\n",
    "    axs[-1].set_xlabel(\"Step\")\n",
    "    axs[-1].set_yticks([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115f4b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_act = [actions_by_time(ppo),actions_by_time(heuristic)]\n",
    "actions = ['dT', 'dV', '1-chlorohexane', '2-chlorohexane', '3-chlorohexane', 'Na' ]\n",
    "colors = [\"r\",\"g\",\"b\",\"c\",\"y\",\"m\"]\n",
    "names=[\"PPO\",\"Heuristic\"]\n",
    "\n",
    "plotabt(all_act,actions,colors,names,title_ext=\"(WurtzReact PPO on 0.5M steps)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24656963",
   "metadata": {},
   "source": [
    "# Functions for Conditional Returns and Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c2ccc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from chemistrylab.reactions.available_reactions.chloro_wurtz import PRODUCTS as CWtargs\n",
    "\n",
    "def get_conditional_rewards(frame,targets=CWtargs):\n",
    "    \"\"\"\n",
    "    Gives returns conditioned on the different targets\n",
    "    Inputs:\n",
    "        Frame (dataframe) - Pandas Dataframe containing gym information\n",
    "        targets (list) - List of N targets (reaction products)\n",
    "        \n",
    "    Outputs:\n",
    "        targets\n",
    "        rew (List<float>) - List of size N containing the average return given each target\n",
    "    \n",
    "    \"\"\"\n",
    "    # turn observation column into a numpy array\n",
    "    obs = np.stack(frame.InState)\n",
    "    N=len(targets)\n",
    "    rew=[]\n",
    "    for i in range(N):\n",
    "        #gather all data where the target is targets[N]\n",
    "        cframe=frame[obs[:,-N+i]>0.9]\n",
    "        #Obtain the mean reward of these episodes\n",
    "        rew+=[cframe[cframe.Done==True].Reward.mean()]\n",
    "    return [targets,np.array(rew)]\n",
    "\n",
    "def get_conditional_actions(frame,targets=CWtargs):\n",
    "    \"\"\"\n",
    "    Gives actions conditioned on the different targets, meant for continuous action spaces\n",
    "    Inputs:\n",
    "        Frame (dataframe) - Pandas Dataframe containing gym information\n",
    "        targets (list) - List of N targets (reaction products)\n",
    "        \n",
    "    Outputs:\n",
    "        targets\n",
    "        act (List<array>) - List of size N containing the mean action given each target\n",
    "    \n",
    "    \"\"\"\n",
    "    # turn observation column into a numpy array\n",
    "    obs = np.stack(frame.InState)\n",
    "    N=len(targets)\n",
    "    act=[]\n",
    "    for i in range(N):\n",
    "        #gather all data where the target is targets[N]\n",
    "        cframe=frame[obs[:,-N+i]>0.9]\n",
    "        #Obtain the mean action of these episodes\n",
    "        act+=[cframe.Action.mean()]\n",
    "    return [targets,act]\n",
    "\n",
    "\n",
    "def target_subset(frame,N,i):\n",
    "    obs = np.stack(frame.InState)\n",
    "    cframe=frame[obs[:,-N+i]>0.9]\n",
    "    return cframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f49cf0",
   "metadata": {},
   "source": [
    "# General Wurtz React:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda1f430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "models = [\"A2C\",\"PPO\",\"SAC\"]\n",
    "\n",
    "gppo = [pd.read_pickle(\"%s_GenWurtzReact-v1/rollout\"%model) for model in models]\n",
    "gheuristic = pd.read_pickle(\"GWRH/rollout\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635a1a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "relative=True\n",
    "\n",
    "if relative:\n",
    "    ghr=get_conditional_rewards(gheuristic)[1]\n",
    "    info = ([get_conditional_rewards(gheuristic)[0]]+\n",
    "[(models[i], [get_conditional_rewards(gppo[i])[1]/ghr]) for i in range(len(models))]+\n",
    "[('Heuristic', [get_conditional_rewards(gheuristic)[1]])])\n",
    "\n",
    "else:\n",
    "    info = ([get_conditional_rewards(gheuristic)[0]]+\n",
    "[(models[i], [get_conditional_rewards(gppo[i])[1]]) for i in range(len(models))]+\n",
    "[('Heuristic', [get_conditional_rewards(gheuristic)[1]])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199f5649",
   "metadata": {},
   "outputs": [],
   "source": [
    "from RadarGraph import *\n",
    "\n",
    "\n",
    "theta = radar_factory(len(info[0]), frame='polygon')\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(22, 7), nrows=1, ncols=len(models)+1,subplot_kw=dict(projection='radar'))\n",
    "fig.subplots_adjust(wspace=0.5, hspace=0.25, top=0.85, bottom=0.05)\n",
    "\n",
    "make_radar(theta,axs,info,colors = \"r\",gridlines=[0.0,0.4,0.8,1.2,1.6,2.0])\n",
    "\n",
    "labels = ('Return', '-', '1', 'Factor 4', 'Factor 5')\n",
    "legend = axs[0].legend(labels, loc=(0.9, .95),labelspacing=0.1, fontsize='small')\n",
    "\n",
    "\n",
    "fig.text(0.5, 0.8, \"Average Return VS Target Material (PPO trained with 0.5M Steps)\",\n",
    "             horizontalalignment='center', color='black', weight='bold',\n",
    "             size='large')\n",
    "\n",
    "if relative:\n",
    "    #scale all but the heurstic the same\n",
    "    for ax in axs.flat[:-1]:\n",
    "        ax.set_rmin(min([a[0].min() for (c,a) in info[1:-1]]+[0]))\n",
    "        ax.set_rmax(max([a[0].max() for (c,a) in info[1:-1]]+[1]))\n",
    "else:\n",
    "    #scale them all the same\n",
    "    for ax in axs.flat:\n",
    "        ax.set_rmin(min([a[0].min() for (c,a) in info[1:]]+[0]))\n",
    "        ax.set_rmax(max([a[0].max() for (c,a) in info[1:]]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e69b899",
   "metadata": {},
   "outputs": [],
   "source": [
    "info0 = ([\n",
    "    ['dT', 'dV', '1-chlorohexane', '2-chlorohexane', '3-chlorohexane', 'Na' ]]+\n",
    "    [(models[i], [[b for b in act] for act in get_conditional_actions(gppo[i])[1]]) for i in range(len(models))]+\n",
    "    [('Heuristic', [[b for b in act] for act in get_conditional_actions(gheuristic)[1]])]\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135ba709",
   "metadata": {},
   "source": [
    "# Mean Action Given a Target Material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcf3c9b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#for i in range(len(CWtargs)):\n",
    "i = 0  \n",
    "\n",
    "info=[info0[0]]+[(md[0],md[1][i:i+1]) for md in info0[1:]]\n",
    "\n",
    "\n",
    "theta = radar_factory(len(info[0]), frame='polygon')\n",
    "fig, axs = plt.subplots(figsize=(22, 4), nrows=1, ncols=len(models)+1,subplot_kw=dict(projection='radar'))\n",
    "fig.subplots_adjust(wspace=0.5, hspace=0.25, top=0.85, bottom=0.05)\n",
    "c=['b', 'r', 'g', 'm', 'y',\"orange\",\"r\"][i:i+1]\n",
    "make_radar(theta,axs,info,colors=c)\n",
    "labels = [\"Target: \"+CWtargs[i]]\n",
    "legend = axs[0].legend(labels, loc=(0.9, .95),labelspacing=0.1, fontsize='small')\n",
    "fig.text(0.5, 1.0, \"Mean Value of Actions VS Target Material (Trained with 0.5M Steps)\",\n",
    "             horizontalalignment='center', color='black', weight='bold',\n",
    "             size='large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c8a651",
   "metadata": {},
   "source": [
    "# Mean action at each timestep (Same Target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453119cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_act = ([\n",
    "actions_by_time(target_subset(gp,len(CWtargs),i)) for gp in gppo]\n",
    "+[actions_by_time(target_subset(gheuristic,len(CWtargs),i))])\n",
    "actions = ['dT', 'dV', '1-chlorohexane', '2-chlorohexane', '3-chlorohexane', 'Na' ]\n",
    "colors = [\"r\",\"g\",\"b\",\"c\",\"y\",\"m\"]\n",
    "names=[\"A2C\",\"PPO\",\"SAC\",\"Heuristic\"]\n",
    "\n",
    "plotabt(all_act,actions,colors,names,title_ext=\"(GenWurtzReact Targeting %s)\"%CWtargs[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb18a962",
   "metadata": {},
   "source": [
    "# Fict React:\n",
    "\n",
    "Reactions at play:\n",
    "\n",
    "A+B $\\rightarrow$ E</br>\n",
    "A+D $\\rightarrow$ F</br>\n",
    "B+D $\\rightarrow$ G</br>\n",
    "F+G $\\rightarrow$ I</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b430979",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chemistrylab.reactions.available_reactions.fict_react2 import PRODUCTS as FRtargs\n",
    "from chemistrylab.reactions.available_reactions.fict_react2 import REACTANTS as FRchoices\n",
    "\n",
    "models = [\"A2C\",\"PPO\",\"SAC\"]\n",
    "\n",
    "fppo = [pd.read_pickle(\"%s_FictReact-v2/rollout\"%model) for model in models]\n",
    "\n",
    "fheuristic = pd.read_pickle(\"FR2H/rollout\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221f53e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "relative=True\n",
    "\n",
    "if relative:\n",
    "    fhr=get_conditional_rewards(fheuristic,FRtargs)[1]\n",
    "    info = ([get_conditional_rewards(fheuristic,FRtargs)[0]]+\n",
    "[(models[i], [get_conditional_rewards(fppo[i],FRtargs)[1]/fhr]) for i in range(len(models))]+\n",
    "[('Heuristic', [get_conditional_rewards(fheuristic,FRtargs)[1]])])\n",
    "\n",
    "else:\n",
    "    info = ([get_conditional_rewards(fheuristic,FRtargs)[0]]+\n",
    "[(models[i], [get_conditional_rewards(fppo[i],FRtargs)[1]]) for i in range(len(models))]+\n",
    "[('Heuristic', [get_conditional_rewards(fheuristic,FRtargs)[1]])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42189af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = radar_factory(len(info[0]), frame='polygon')\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(22, 7), nrows=1, ncols=len(models)+1,subplot_kw=dict(projection='radar'))\n",
    "\n",
    "#axs = np.array([axs])\n",
    "\n",
    "fig.subplots_adjust(wspace=0.5, hspace=0.25, top=0.85, bottom=0.05)\n",
    "\n",
    "make_radar(theta,axs,info,colors = \"r\",gridlines=[0.0,0.2,0.4,0.6,0.8])\n",
    "\n",
    "labels = ('Return', '-', '1', 'Factor 4', 'Factor 5')\n",
    "legend = axs[0].legend(labels, loc=(0.9, .95),labelspacing=0.1, fontsize='small')\n",
    "\n",
    "\n",
    "fig.text(0.5, 0.8, \"Average Return VS Target Material (PPO trained with 0.5M Steps)\",\n",
    "             horizontalalignment='center', color='black', weight='bold',\n",
    "             size='large')\n",
    "\n",
    "if relative:\n",
    "    #scale all but the heurstic the same\n",
    "    for ax in axs.flat[:-1]:\n",
    "        ax.set_rmin(min([a[0].min() for (c,a) in info[1:-1]]+[0]))\n",
    "        ax.set_rmax(max([a[0].max() for (c,a) in info[1:-1]]+[1]))\n",
    "else:\n",
    "    #scale them all the same\n",
    "    for ax in axs.flat:\n",
    "        ax.set_rmin(min([a[0].min() for (c,a) in info[1:]]+[0]))\n",
    "        ax.set_rmax(max([a[0].max() for (c,a) in info[1:]]))\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e47715",
   "metadata": {},
   "source": [
    "# Mean Action VS Target Material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cbf586",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(len(FRtargs)):\n",
    "i=0   \n",
    "info=[info0[0]]+[(md[0],md[1][i:i+1]) for md in info0[1:]]\n",
    "\n",
    "\n",
    "theta = radar_factory(len(info[0]), frame='polygon')\n",
    "fig, axs = plt.subplots(figsize=(22, 4), nrows=1, ncols=len(models)+1,subplot_kw=dict(projection='radar'))\n",
    "fig.subplots_adjust(wspace=0.5, hspace=0.25, top=0.85, bottom=0.05)\n",
    "c=['b', 'r', 'g', 'm', 'y',\"orange\",\"r\"][i:i+1]\n",
    "make_radar(theta,axs,info,colors=c)\n",
    "labels = [\"Target: \"+FRtargs[i]]\n",
    "legend = axs[0].legend(labels, loc=(0.9, .95),labelspacing=0.1, fontsize='small')\n",
    "fig.text(0.5, 1.0, \"Mean Value of Actions VS Target Material (Trained with 0.5M Steps)\",\n",
    "             horizontalalignment='center', color='black', weight='bold',\n",
    "             size='large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b226a48",
   "metadata": {},
   "source": [
    "# ... At each Timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0577796e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_act = ([\n",
    "actions_by_time(target_subset(fp,len(FRtargs),i)) for fp in fppo]\n",
    "+[actions_by_time(target_subset(fheuristic,len(FRtargs),i))])\n",
    "colors = [\"r\",\"g\",\"b\",\"c\",\"y\",\"m\"]\n",
    "names=[\"A2C\",\"PPO\",\"SAC\",\"Heuristic\"]\n",
    "\n",
    "plotabt(all_act,FRchoices,colors,names,title_ext=\"(FictReact Targeting %s)\"%FRtargs[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bd4e26",
   "metadata": {},
   "source": [
    "# Handling Box-Discrete actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a993d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_discrete_actions(frame,N=None):\n",
    "    \"\"\"\n",
    "    Gives distribution of actions (index 0) taken as well as the average value of the actions at index 1\n",
    "    Inputs:\n",
    "        Frame (dataframe) - Pandas Dataframe containing gym information        \n",
    "    Outputs:\n",
    "        act0 (list<float>) - Action (index 0) distribution\n",
    "        act1 (list(float)) - Average action at index 1\n",
    "    \n",
    "    \"\"\"\n",
    "    # turn observation column into a numpy array\n",
    "    act = np.stack(frame.Action)    \n",
    "    if N is None:\n",
    "        N = np.max(act[:,0])\n",
    "    N0= np.max(act[:,1])\n",
    "    act0=[]\n",
    "    act1=[]\n",
    "    #print(N)\n",
    "    for i in range(N+1):\n",
    "        #gather all data where the target is targets[N]\n",
    "        cframe=frame[act[:,0]==i]\n",
    "        \n",
    "        #print(cframe)\n",
    "        #Obtain the mean action of these episodes\n",
    "        act0+=[len(cframe.Action)/act.shape[0]]\n",
    "        if len(cframe.Action)==0:\n",
    "            act1+=[0]\n",
    "        else:\n",
    "            act1+=[cframe.Action.mean()[1]/N0]\n",
    "    return [act0,act1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d37e01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discrete_actions_by_time(frame,N=None):\n",
    "    \"\"\"Gives the mean action at each timestep of your rollout dataframe when actions are discrete\"\"\"\n",
    "    min_t,max_t = frame.Step.min(),frame.Step.max()\n",
    "    mean_act=[]\n",
    "    \n",
    "    act = np.stack(frame.Action)  \n",
    "    if N is None:\n",
    "        N = np.max(act[:,0])\n",
    "    \n",
    "    for t in range(min_t,max_t+1):\n",
    "        act = np.stack(frame.Action[frame.Step==t])\n",
    "        mean_act_t =np.zeros(N+1)\n",
    "        for i in range(N+1):\n",
    "            mean_act_t[i] = (act[:,0]==i).mean()\n",
    "        mean_act+=[mean_act_t]\n",
    "    return np.array(mean_act)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e504cd",
   "metadata": {},
   "source": [
    "# Distillation Bench Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5347cca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"A2C\",\"PPO\"]\n",
    "dppo = [pd.read_pickle(\"%s_WurtzDistill-v1/rollout\"%model) for model in models]\n",
    "dheuristic = pd.read_pickle(\"WDH/rollout\")\n",
    "#dheuristic = pd.read_pickle(\"FR2H/rollout\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a553c08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = ([['dT', 'Pour 0->1', 'Pour 1->2', 'Wait', 'End Experiment' ]]+\n",
    "[(models[i], get_discrete_actions(dppo[i],N=4)[::-1]+\n",
    " [[dppo[i][dppo[i].Done==True].Reward.mean()]*5]\n",
    " ) for i in range(len(models))]+\n",
    "[('Heuristic', get_discrete_actions(dheuristic,N=4)[::-1]\n",
    "+[[dheuristic[dheuristic.Done==True].Reward.mean()]*5])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d2e21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = radar_factory(len(info[0]), frame='polygon')\n",
    "fig, axs = plt.subplots(figsize=(22, 4), nrows=1, ncols=len(models)+1,subplot_kw=dict(projection='radar'))\n",
    "fig.subplots_adjust(wspace=0.5, hspace=0.25, top=0.85, bottom=0.05)\n",
    "c=['b', 'r', 'g', 'm', 'y',\"orange\",\"r\"]#[i:i+1]\n",
    "make_radar(theta,axs,info,colors=c)\n",
    "labels = ( 'Action average sub-value','Percent Action Taken',\"Average Return\")\n",
    "legend = axs[0].legend(labels, loc=(0.9, .95),labelspacing=0.1, fontsize='small')\n",
    "fig.text(0.5, 1.0, \"Comparison of the frequency of actions taken (Trained with 50K Steps)\",\n",
    "             horizontalalignment='center', color='black', weight='bold',\n",
    "             size='large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b1ed2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_act = ([\n",
    "discrete_actions_by_time(dp,N=4) for dp in dppo[1:]]\n",
    "+[discrete_actions_by_time(dheuristic,N=4)])\n",
    "colors = [\"r\",\"g\",\"b\",\"c\",\"y\",\"m\"]\n",
    "names=[\"PPO\",\"Heuristic\"]\n",
    "actions=['dT', 'Pour 0->1', 'Pour 1->2', 'Wait', 'End Experiment' ]\n",
    "plotabt(all_act,actions,colors,names,title_ext=\"(WurtzDistill)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab4ef74",
   "metadata": {},
   "source": [
    "# Extraction Bench Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9b7eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"A2C\",\"PPO\"]\n",
    "eppo = [pd.read_pickle(\"%s_WurtzExtract-v1/rollout\"%model) for model in models]\n",
    "\n",
    "eheuristic = pd.read_pickle(\"WEH/rollout\")\n",
    "\n",
    "#action_set = ['Draining from ExV to Beaker1', 'Mix ExV', \"Mix B1\", \"Mix B2\", \"Pour from B1 to ExV\", \"Pour from B1 to B2\",\n",
    "#              'Pour from ExV to B2', 'Add oil, pour from Oil Vessel to ExV', 'wait', 'Done']\n",
    "\n",
    "action_set=[\"Drain EV to B1\", \"Mix EV\",\"Pour B1 into EV\",\"Pour B2 into EV\", \n",
    "            \"Pour EV into B2\", \"Pour S1 into EV\", \"Pour S2 into EV\",\"End Experiment\"]\n",
    "\n",
    "\n",
    "N = len(action_set)-1\n",
    "info = ([action_set]+\n",
    "[(models[i], get_discrete_actions(eppo[i],N)[::-1]+\n",
    " [[eppo[i][eppo[i].Done==True].Reward.mean()]*(N+1)]\n",
    " ) for i in range(len(models))]+\n",
    "[('Heuristic', get_discrete_actions(eheuristic,N)[::-1]\n",
    "+[[eheuristic[eheuristic.Done==True].Reward.mean()]*(N+1)])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48005720",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = radar_factory(len(info[0]), frame='polygon')\n",
    "fig, axs = plt.subplots(figsize=(22, 4), nrows=1, ncols=len(models)+1,subplot_kw=dict(projection='radar'))\n",
    "fig.subplots_adjust(wspace=0.5, hspace=0.25, top=0.85, bottom=0.05)\n",
    "c=['b', 'r', 'g', 'm', 'y',\"orange\",\"r\"]#[i:i+1]\n",
    "make_radar(theta,axs,info,colors=c)\n",
    "labels = ( 'Action average sub-value','Percent Action Taken',\"Average Return\")\n",
    "legend = axs[0].legend(labels, loc=(0.9, .95),labelspacing=0.1, fontsize='small')\n",
    "fig.text(0.5, 1.0, \"Comparison of the frequency of actions taken (Trained with 50K Steps)\",\n",
    "             horizontalalignment='center', color='black', weight='bold',\n",
    "             size='large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c7b5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions=[\"Drain EV to B1\", \"Mix EV\",\"Pour B1 into EV\",\"Pour B2 into EV\", \n",
    "            \"Pour EV into B2\", \"Pour S1 into EV\", \"Pour S2 into EV\",\"End Experiment\"]\n",
    "N = len(actions)-1\n",
    "\n",
    "all_act = ([\n",
    "discrete_actions_by_time(ep,N) for ep in eppo]\n",
    "+[discrete_actions_by_time(eheuristic,N)])\n",
    "colors = [\"r\",\"g\",\"b\",\"c\",\"y\",\"m\"]\n",
    "names=[\"A2C\",\"PPO\",\"Heuristic\"]\n",
    "\n",
    "plotabt(all_act,actions,colors,names,title_ext=\"(WurtzExtract)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2bad97",
   "metadata": {},
   "outputs": [],
   "source": [
    "1/0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2076ec8",
   "metadata": {},
   "source": [
    "# React Bench Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fca714",
   "metadata": {},
   "outputs": [],
   "source": [
    "for algo in [\"PPO\",\"SAC\",\"A2C\"]:\n",
    "    os.system(\"python RLTrain.py algorithm=%s environment=GenWurtzReact-v1 steps=500000\"%algo)\n",
    "    \n",
    "for algo in [\"PPO\",\"SAC\",\"A2C\"]:\n",
    "    os.system(\"python RLTrain.py algorithm=%s environment=FictReact-v2 steps=500000\"%algo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e37ee20",
   "metadata": {},
   "source": [
    "# Extraction and Distillation Bench Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513a4541",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#from RLTrain import ALGO\n",
    "#print (ALGO)\n",
    "for algo in ['PPO', 'A2C']:\n",
    "    os.system(\"python RLTrain.py algorithm=%s environment=GenWurtzExtract-v1 steps=50000\"%algo)\n",
    "    os.system(\"python RLTrain.py algorithm=%s environment=WurtzDistill-v1 steps=50000\"%algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8cd3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for algo in ['PPO', 'A2C']:\n",
    "    os.system(\"python RLTrain.py algorithm=%s environment=WurtzExtract-v1 steps=50000\"%algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abcd183",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = \"A2C\"\n",
    "os.system(\"python RLTrain.py algorithm=%s environment=WurtzDistill-v1 steps=50000\"%algo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f39355",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9cacf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "for a,b,c in os.walk(\"./\"):\n",
    "    #print(a)\n",
    "    if \"-v\" in a and not \"Legacy\" in a:\n",
    "        print(a[2:])\n",
    "        os.system(\"python RLTest.py %s steps=5000\"%a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0403c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(\"python RLTest.py WDH environment=WurtzDistill-v1 algorithm=WDH steps=5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3f7ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in [\"PPO_WurtzDistill-v1\",\"A2C_WurtzDistill-v1\"]:\n",
    "    os.system(\"python RLTest.py %s steps=5000\"%a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6209bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(\"python RLTest.py WEH environment=WurtzExtract-v1 algorithm=WEH steps=5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195e463a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dheuristic = pd.read_pickle(\"WDH/rollout\")\n",
    "dheuristic[dheuristic.Done==True].Reward.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b191762d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eheuristic = pd.read_pickle(\"WEH/rollout\")\n",
    "eheuristic[dheuristic.Done==True].Reward.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575793dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [\"1\",\"2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555110b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.system(\"python RLTest.py FR2H environment=FictReact-v2 algorithm=FR2H steps=5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7c04d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
