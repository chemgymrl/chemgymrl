{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e09a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from RLTrain import Opt\n",
    "import os\n",
    "import time\n",
    "#print(Opt())\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib.scale import FuncScale\n",
    "from RadarGraph import *\n",
    "#plt.rcParams[\"font.size\"]=14.0\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from visualization_helper import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d5e395",
   "metadata": {},
   "source": [
    "# Methods for Trajectory parsing and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3ac2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashed_trajectories(frame,N=None,N2=None,gamma=1):\n",
    "    \"\"\"Turns rollouts into a dictionary of trajectories and counts by hashing episodes based on the actions taken.\n",
    "    \n",
    "    Args:\n",
    "    - frame (dataframe):   Pandas Dataframe containing rollouts\n",
    "    - N (int):             Number of actions in MultiDiscrete dim 0\n",
    "    - N2 (int):            Number of actions in MultiDiscrete dim 1\n",
    "    \n",
    "    Returns:\n",
    "    - trajectories (dict): String representations of actions are keys and values are of the form (count,mean_return)\n",
    "    \n",
    "    Example: \n",
    "    \n",
    "    >>> print(frame) \n",
    "    >>>         InState  Action  Reward  OutState   Done Info  Step\n",
    "            0  0.631918  [0, 9]     0.0  0.632225  False   {}     0\n",
    "            1  0.632225  [0, 9]     0.0    0.6319  False   {}     1\n",
    "            2    0.6319  [4, 4]     0.8    0.6319   True   {}     2\n",
    "            \n",
    "    >>> hashed_trajectories(frame)\n",
    "    >>> {'090944': 1}\n",
    "    \n",
    "    \"\"\"\n",
    "    min_t,max_t = frame.Step.min(),frame.Step.max()\n",
    "    mean_act=[]\n",
    "    \n",
    "    act = np.stack(frame.Action)  \n",
    "\n",
    "    trajectories=dict()\n",
    "    \n",
    "    if N is None:\n",
    "        N = np.max(act[:,0])\n",
    "    act_string=\"\"\n",
    "    ret=0\n",
    "    for t,act in enumerate(frame.Action):\n",
    "        if frame.Step[t]==0:\n",
    "            act_string=\"\"\n",
    "            ret=0\n",
    "        if len(act.shape)<1:\n",
    "            act0=int(act)\n",
    "            act=np.zeros((2,),dtype=np.int32)\n",
    "            act[0]=act0//N2\n",
    "            act[1] = act0%N2\n",
    "        act_string+=(str(act[0])+str(act[1]))\n",
    "        ret += frame.Reward[t]*gamma**frame.Step[t]\n",
    "        if frame.Done[t]:\n",
    "            count,ret0 = trajectories.get(act_string,(0,0))\n",
    "            trajectories[act_string] = (count+1,(ret+count*ret0)/(count+1))\n",
    "            \n",
    "            \n",
    "    return trajectories\n",
    "\n",
    "\n",
    "\n",
    "def relabel_trajectory(trajectory:dict,pouring_actions:set,wait_string:str,\n",
    "                       end_string,bins_per_action:int,default_wait=\"1\",dependencies=dict()):\n",
    "    \"\"\"\n",
    "    Method to re-label a trajectory such that actions that don't do anything are replaced with waiting and\n",
    "    the end experiment actions all have the same sub-action value\n",
    "    \"\"\"\n",
    "    new_trajectory=\"\"\n",
    "    center=str(int(bins_per_action//2))\n",
    "    i_dependencies={dependencies[a]:a for a in dependencies}\n",
    "    satisfied= {a:0 for a in dependencies}\n",
    "    \n",
    "    for action,param in zip(trajectory[::2],trajectory[1::2]):\n",
    "        \n",
    "        if param!=\"0\" and action in i_dependencies:\n",
    "            satisfied[i_dependencies[action]]+=1\n",
    "        if param==\"0\" and action in pouring_actions:\n",
    "            #Pouring zero amount is the same as waiting\n",
    "            action=wait_string\n",
    "            param=default_wait\n",
    "        elif action in dependencies and not satisfied[action]:\n",
    "            action=wait_string\n",
    "            param=default_wait\n",
    "        #standardize the end experiment action\n",
    "        if action == end_string:\n",
    "            param=center\n",
    "            \n",
    "        new_trajectory+=action+param\n",
    "                \n",
    "    return new_trajectory\n",
    "\n",
    "def relabel_trajectories(trajectories:dict,pouring_actions:set,wait_string:str,\n",
    "                         end_string,bins_per_action:int,default_wait=\"1\",dependencies=dict(),use_return=False):\n",
    "    \"\"\"\n",
    "    Recompute a trajectory dictionary using relabel_trajectory\n",
    "    \"\"\"\n",
    "    new_traj=dict()\n",
    "    #make function calls easier\n",
    "    relabel=lambda x: relabel_trajectory(x,pouring_actions,wait_string,end_string,bins_per_action,default_wait,dependencies)\n",
    "    \n",
    "    for key in trajectories:\n",
    "        key2 = relabel(key)\n",
    "        #get new count and average return\n",
    "        count0,ret0 = trajectories[key]\n",
    "        count,ret = new_traj.get(key2,(0,0))\n",
    "        new_traj[key2] = (count0+count,(ret*count+count0*ret0)/(count0+count))\n",
    "            \n",
    "    return new_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc6d6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stat_key(traj,stat=\"median\",tol=1e-6):\n",
    "    sorted_hashes = sorted([a for a in traj],key=lambda x:traj[x][1],reverse=True)\n",
    "    sorted_amounts = np.array([traj[x][0] for x in sorted_hashes])\n",
    "    median_count=sorted_amounts.sum()/2\n",
    "    total_count=0\n",
    "    \n",
    "    if stat==\"min\":\n",
    "        stat_key = sorted_hashes[-1]\n",
    "    elif stat==\"max\":\n",
    "        stat_key = sorted_hashes[0]\n",
    "    else:\n",
    "      for i,count in enumerate(sorted_amounts):\n",
    "        total_count+=count\n",
    "        if total_count>=median_count:\n",
    "            stat_key = sorted_hashes[i]\n",
    "    \n",
    "    return stat_key\n",
    "    stat_return=traj[stat_key][1]\n",
    "    for key in traj:\n",
    "        count,ret=traj[key]\n",
    "        #if abs(ret-stat_return)<tol:print(ret,,count)\n",
    "        if abs(ret-stat_return)<tol and (count>traj[stat_key][0] or (count==traj[stat_key][0] and len(key)<len(stat_key))):\n",
    "            stat_key=key\n",
    "    return stat_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1c972d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_trajectories(trajectories:dict, actions, bins_per_action, figsize=(7,3),\n",
    "                      alpha_map=lambda x:x**2, max_allowed=1e6, fig_ax=None, L=None,use_return=False, **kwargs):\n",
    "\n",
    "    \"\"\"\n",
    "    Plots a dictionary of hashed trajectories with transparency based off of the alpha map\n",
    "    \n",
    "    Args:\n",
    "    - trajectories (dict): Dictionary where keys are the trajectories and values are weights \n",
    "            (ex: keys are number trajectory counts, or reward achieved with the trajectory)\n",
    "    - actions (list of str): List of the names of each action\n",
    "    - bins_per_action (int): The number of bins for each main action in the multidiscrete\n",
    "    - figsize (tuple): The size you want the figure to be\n",
    "    - alpha_map (function): A function that translates normalized values (divided by the max to fit in (-inf,1))\n",
    "            to alpha values\n",
    "    - max_allowed (float): The maximum number of trajectories which can be plotted\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    b = bins_per_action\n",
    "    tograph = lambda x: [int(i)*10+float(x[2*j+1])*7.8/b+(9-9*.78)/2 for j,i in enumerate(x[::2])]\n",
    "    \n",
    "    #order the dict based on frequency\n",
    "    sorted_hashes = sorted([a for a in trajectories],key=lambda x:trajectories[x][use_return],reverse=True)\n",
    "    sorted_amounts = [trajectories[x][use_return] for x in sorted_hashes]\n",
    "    \n",
    "    #scale the graph\n",
    "    if L is None:\n",
    "        L=max(12,len(sorted_hashes[0])//2)\n",
    "    \n",
    "    if fig_ax is None:\n",
    "        fig = plt.figure(1,figsize=figsize, dpi=240, facecolor='w', edgecolor='k')\n",
    "        ax=plt.gca()\n",
    "\n",
    "        for j,act in enumerate(actions[::-1]):\n",
    "            j=len(actions)-j-1\n",
    "            plt.fill_between([-0.5,L],[j*10-0.5,j*10-0.5],[j*10+9.5,j*10+9.5],alpha=0.5)\n",
    "            plt.text(L*0.9875,j*10+5,act,horizontalalignment=\"right\",bbox=dict(boxstyle=\"square\",facecolor=\"w\",edgecolor=\"k\",alpha=0.2))\n",
    "\n",
    "        plt.xlabel(\"Step\")\n",
    "        plt.ylabel(\"Action\")\n",
    "        plt.xlim(-0.5,L)\n",
    "        plt.ylim(-0.5,len(actions)*10-0.5)\n",
    "        plt.yticks([])\n",
    "    \n",
    "    \n",
    "    else:\n",
    "        fig,ax=fig_ax\n",
    "    for a,string in enumerate(sorted_hashes):\n",
    "        if a<max_allowed:\n",
    "            plt.plot(tograph(string),\".-\",alpha=alpha_map(sorted_amounts[a]/sorted_amounts[0]),**kwargs)\n",
    "        else:break\n",
    "            \n",
    "\n",
    "    return fig,ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40482243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_heatmap(frame,N=None,N2=None,use_return=False):\n",
    "    \"\"\"Turns rollouts into an array which counts the number of times an action was taken at a certain step\n",
    "    \n",
    "    Args:\n",
    "    - frame (dataframe):   Pandas Dataframe containing rollouts\n",
    "    - N (int):             Number of actions in MultiDiscrete dim 0\n",
    "    - N2 (int):            Number of actions in MultiDiscrete dim 1\n",
    "    \n",
    "    Returns:\n",
    "    - heatmap (np.array): the heatmap\n",
    "    \"\"\"\n",
    "    \n",
    "    min_t,max_t = frame.Step.min(),frame.Step.max()\n",
    "    \n",
    "    act = np.stack(frame.Action)  \n",
    "\n",
    "    \n",
    "    \n",
    "    if N is None:\n",
    "        N = np.max(act[:,0])\n",
    "    \n",
    "    heatmap=np.zeros([max_t+1,(N+1)*N2])\n",
    "        \n",
    "    for t,act in enumerate(frame.Action):\n",
    "        if len(act.shape)<1:\n",
    "            act0=int(act)\n",
    "            act=np.zeros((2,),dtype=np.int32)\n",
    "            act[0]=act0//N2\n",
    "            act[1] = act0%N2\n",
    "        heatmap[frame.Step[t],act[0]*N2+act[1]]+=1\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839f2ddb",
   "metadata": {},
   "source": [
    "# Distillation Bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0796e38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parent_dir = \"MODELS\\\\GenWurtzDistill-v1\"\n",
    "folders = load_rollouts(parent_dir,obj=max_obj,last=False,verbose=False)\n",
    "\n",
    "if \"Heuristic\" in folders:\n",
    "    dheuristic=folders[\"Heuristic\"]\n",
    "    del folders[\"Heuristic\"]\n",
    "else:\n",
    "    dheuristic = pd.read_pickle(\"MODELS\\\\WurtzDistill-v1\\\\Heuristic\\\\rollout\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4a6179",
   "metadata": {},
   "source": [
    "## Results During Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c98dc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1,figsize=(8,6), dpi=240, facecolor='w', edgecolor='k')\n",
    "\n",
    "colors = [\"r\",\"g\",\"m\",\"b\",\"y\",\"c\",\"k\"]\n",
    "points = ['s', '+', 'x', '.','p',\"*\",\"D\"]\n",
    "\n",
    "\n",
    "\n",
    "for i,algo in enumerate(folders):\n",
    "    subf = parent_dir+\"\\\\\"+algo\n",
    "    returns,counts=merge_varying_graphs(subf,steps=200,separate_runs=False)    \n",
    "    #Average over the different runs\n",
    "    mean,stdv,steps,n= mean_stdv_step_n(returns,interp_steps=1,steps=200)\n",
    "    \n",
    "    plt.plot(steps,mean,\"-\",marker=points[i],color=colors[i],label=algo,ms=3,lw=0.5)\n",
    "    plt.fill_between(steps,mean-stdv,mean+stdv,color=colors[i],alpha=0.4,lw=0)\n",
    "    \n",
    "plt.xlim(steps[0],np.ceil(steps[-1]/1e3)*1e3)\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Return\")\n",
    "\n",
    "plt.plot([steps[0],np.ceil(steps[-1]/1e3)*1e3],[0.82,0.82],\"k--\",label=\"Best Possible Return\")\n",
    "\n",
    "plt.plot([0,1e5],[0.0,0.0],\"k-\")\n",
    "\n",
    "plt.legend(loc=\"lower right\")  \n",
    "\n",
    "#plt.yscale(FuncScale(plt.gca(),(lambda x: x*(x>0)+x*(x<=0)/20,lambda x: x*(x>0)+x*(x<=0)*20)))\n",
    "#plt.yticks([-60,-40,-20,0,1])\n",
    "\n",
    "plt.ylim(-5,1)\n",
    "\n",
    "\n",
    "\n",
    "plt.title(\"WurtzDistill-v1 Average Return vs Sequential Step \\n (10 envs in used in parallel, average over 10 runs)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7de42c",
   "metadata": {},
   "source": [
    "# Looking at trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e734f264",
   "metadata": {},
   "outputs": [],
   "source": [
    "CWtargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a5b1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def salt_check(frame,get_salt=True,has_salt_targ=False):\n",
    "    is_salty = np.array([a[\"NaCl\"] for a in frame.Info])\n",
    "    if get_salt:\n",
    "        cframe=frame[is_salty]\n",
    "    else:\n",
    "        cframe=frame[~is_salty]\n",
    "        \n",
    "    if not has_salt_targ:\n",
    "        obs = np.stack(cframe.InState)\n",
    "        cframe=cframe[obs[:,0,-1]<0.9]\n",
    "        \n",
    "    cframe=pd.concat([cframe],ignore_index=True)\n",
    "    return cframe\n",
    "\n",
    "\n",
    "#salt_check(folders[\"DQN\"],False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936cb204",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = ['dT', 'Pour 0->1', 'Pour 1->2', 'Wait', 'End Experiment' ]\n",
    "\n",
    "cframe=salt_check(folders[\"PPO-XL\"],True)\n",
    "print(cframe.shape)\n",
    "\n",
    "raw_trajectories=hashed_trajectories(cframe,N=4,N2=10)\n",
    "\n",
    "\n",
    "quantized_trajectories=raw_trajectories\n",
    "\n",
    "sizes=np.array([quantized_trajectories[a] for a in quantized_trajectories])\n",
    "\n",
    "ratio=sizes.max()/np.sum(sizes)*2\n",
    "\n",
    "show_trajectories(quantized_trajectories,actions,10,alpha_map=lambda x:x*ratio,color=\"k\")\n",
    "plt.title(\"PPO Most Common Trajectories (Distillation Bench: All 10 runs, Best Checkpoint)\")\n",
    "#plt.yticks([1,4.5,8,11,18,21,28,31,38],[-1,0,1,0,1,0,1,0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f32d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors={\"PPO\":\"darkgreen\",\"PPO-XL\":\"darkred\",\"A2C\":\"darkgoldenrod\",\"DQN\":\"darkblue\"}\n",
    "markers={\"PPO\":\".\",\"PPO-XL\":\"*\",\"A2C\":\"^\",\"DQN\":\"2\"}\n",
    "\n",
    "figax=None\n",
    "legend=[]\n",
    "for alg in [\"DQN\",\"A2C\",\"PPO\",\"PPO-XL\"]:\n",
    "\n",
    "    cframe=salt_check(folders[alg],True)\n",
    "    \n",
    "    raw_trajectories=hashed_trajectories(cframe,N=4,N2=10,gamma=1.0)\n",
    "    #quantized_trajectories=raw_trajectories\n",
    "    \n",
    "    info_key=get_stat_key(raw_trajectories,\"max\")\n",
    "    print(info_key)\n",
    "    info_dict={info_key:raw_trajectories[info_key]}\n",
    "    label=alg+\" (%.2f)\"%raw_trajectories[info_key][1]\n",
    "    \n",
    "    figax=show_trajectories(info_dict, actions, 10, figsize=(16,4), max_allowed=1, fig_ax=figax,L=24,ms=8,color=colors[alg],marker=markers[alg],label=label)\n",
    "\n",
    "figax[1].legend(loc=(0.5,0.7),fontsize=8)\n",
    "\n",
    "plt.savefig(\"Legacy\\\\Figures\\\\Extraction\\\\All_Trajectories.pdf\")\n",
    "\n",
    "plt.title(\"Best Trajectory\")\n",
    "\n",
    "#plt.yticks([1,4.5,8,11,18,21,28,31,38],[-1,0,1,0,1,0,1,0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49930a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for alg in [\"DQN\",\"A2C\",\"PPO\",\"PPO-XL\"]:\n",
    "    \n",
    "    quantized_trajectories = hashed_trajectories(folders[alg],N=4,N2=10)    \n",
    "    sizes=np.array(sorted([quantized_trajectories[a][0] for a in quantized_trajectories]))\n",
    "    ratio=sizes.max()/np.sum(sizes[-100:])*4\n",
    "    print(sizes.max())\n",
    "    map_=lambda x:np.clip(x*ratio,0,1)\n",
    "    show_trajectories(quantized_trajectories,actions,10,figsize=(8,4),alpha_map=map_,L=15,color=colors[alg],marker=markers[alg],\n",
    "                     max_allowed=1e2)\n",
    "    plt.savefig(f\"Legacy\\\\Figures\\\\Extraction\\\\Traj{alg}.pdf\",bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122ae069",
   "metadata": {},
   "source": [
    "# Extraction Bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6006f00e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parent_dir = \"MODELS\\\\WurtzExtract-v2\"\n",
    "#parent_dir=\"MODELS\\\\DiscreteWurtzExtract-v1\\\\PPO-XL\\\\13-03-2023--06-08-15\"\n",
    "folders = load_rollouts(parent_dir,obj=,last=False)\n",
    "\n",
    "if \"Heuristic\" in folders:\n",
    "    eheuristic=folders[\"Heuristic\"]\n",
    "    del folders[\"Heuristic\"]\n",
    "else:\n",
    "    eheuristic = pd.read_pickle(\"MODELS\\\\WurtzExtract-v1\\\\Heuristic\\\\rollout\")\n",
    "    \n",
    "    \n",
    "    \n",
    "ACTIONS_V2=[\"Drain EV to B1\", \"Mix EV\",\"Pour B2 into EV\",\"Pour B1 into EV\", \n",
    "        \"Pour EV into B2\", \"Pour S1 into EV\", \"Pour S2 into EV\",\"Wait\",\"End Experiment\"]\n",
    "\n",
    "\n",
    "ACTIONS_V1=[\"Drain EV to B1\", \"Mix EV\",\"Pour B1 into EV\",\"Pour B2 into EV\", \n",
    "            \"Pour EV into B2\", \"Pour S1 into EV\", \"Pour S2 into EV\",\"End Experiment\",\"Wait (Implicit)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3ca4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "del folders[\"PPO-XL\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9735b8",
   "metadata": {},
   "source": [
    "## Results During Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29011a94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(1,figsize=(8,6), dpi=240, facecolor='w', edgecolor='k')\n",
    "\n",
    "colors = [\"r\",\"g\",\"m\",\"b\",\"y\",\"c\",\"k\"]\n",
    "points = ['s', '+', 'x', '.','p',\"*\",\"D\"]\n",
    "\n",
    "for i,algo in enumerate(folders):\n",
    "    subf = parent_dir+\"\\\\\"+algo\n",
    "    returns,counts=merge_varying_graphs(subf,steps=512,separate_runs=False)    \n",
    "    #Average over the different runs\n",
    "    mean,stdv,steps,n= mean_stdv_step_n(returns,interp_steps=1,steps=512)\n",
    "    \n",
    "    plt.plot(steps,mean,\"-\",marker=points[i],color=colors[i],label=algo,ms=3,lw=0.5)\n",
    "    plt.fill_between(steps,mean-stdv,mean+stdv,color=colors[i],alpha=0.4,lw=0)\n",
    "    \n",
    "    \n",
    "plt.plot([steps[0],np.ceil(steps[-1]/1e3)*1e3],[4/7+4/700,4/7+4/700],\"k--\",label=\"Best Possible Return\")\n",
    "\n",
    "plt.plot([0,1e5],[0.0,0.0],\"k-\",lw=1)\n",
    "    \n",
    "plt.xlim(steps[0],np.ceil(steps[-1]/1e3)*1e3)\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Return\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.ylim(-1,0.8)\n",
    "#plt.yscale(FuncScale(plt.gca(),(lambda x: x*(x>0)+x*(x<=0)/10,lambda x: x*(x>0)+x*(x<=0)*10)))\n",
    "plt.yticks([-0.5,0,0.5])\n",
    "plt.savefig(\"Legacy\\\\Figures\\\\GenExtraction2\\\\Extract2runs.pdf\",bbox_inches=\"tight\")\n",
    "plt.title(\"WurtzExtract-v2 Average Return vs Sequential Step \\n (10 envs in used in parallel, average over 10 runs)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc309609",
   "metadata": {},
   "source": [
    "# Looking at Trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575dc99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = folders[\"PPO-XL\"]\n",
    "obs = np.stack(frame.InState)\n",
    "obs=obs[:,0,:]\n",
    "cond = (obs[:,-1]>0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acf2732",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame[cond].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8391cfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "11481*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fd58b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N=len(CWtargs)\n",
    "\n",
    "figax=None  \n",
    "\n",
    "\n",
    "\n",
    "for i,targ in enumerate(CWtargs):\n",
    "\n",
    "    subset = target_subset(folders[\"PPO\"],N,i)\n",
    "            \n",
    "    raw_trajectories=hashed_trajectories(subset,N=7,N2=5)\n",
    "    #quantized_trajectories=relabel_trajectories(raw_trajectories,{\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"},\"8\",\"7\",5,default_wait=\"0\",dependencies=dependencies,use_return=True)\n",
    "    \n",
    "    quantized_trajectories=raw_trajectories\n",
    "    \n",
    "    info_key=get_stat_key(raw_trajectories,\"max\")\n",
    "    \n",
    "    print(info_key)\n",
    "        \n",
    "    info_dict={info_key:quantized_trajectories[info_key]}\n",
    "    \n",
    "    label=targ+\" (%.2f)\"%quantized_trajectories[info_key][1]\n",
    "    \n",
    "    \n",
    "    figax=show_trajectories(info_dict, actions, 5, figsize=(16,4), max_allowed=1,\n",
    "                            fig_ax=figax, L=30, use_return=False, ms=8, label=label)\n",
    "\n",
    "    \n",
    "figax[1].legend(loc=(0.5,0.7),fontsize=8)\n",
    "\n",
    "plt.savefig(\"Legacy\\\\Figures\\\\GenExtraction2\\\\All_Trajectories.pdf\")\n",
    "\n",
    "plt.title(\"Best Trajectory\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a58572",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "actions=ACTIONS_V2\n",
    "\n",
    "dependencies={\"2\":\"0\",\"3\":\"4\"}\n",
    "colors={\"PPO\":\"darkgreen\",\"PPO-XL\":\"darkred\",\"A2C\":\"darkgoldenrod\",\"DQN\":\"darkblue\"}\n",
    "markers={\"PPO\":\".\",\"PPO-XL\":\"*\",\"A2C\":\"^\",\"DQN\":\"2\"}\n",
    "figax=None\n",
    "\n",
    "legend=[]\n",
    "\n",
    "for alg in [\"DQN\",\"A2C\",\"PPO\",\"PPO-XL\"]:\n",
    "\n",
    "\n",
    "    \n",
    "    raw_trajectories=hashed_trajectories(folders[alg],N=7,N2=5)\n",
    "    #quantized_trajectories=relabel_trajectories(raw_trajectories,{\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"},\"8\",\"7\",5,default_wait=\"0\",dependencies=dependencies,use_return=True)\n",
    "    \n",
    "    quantized_trajectories=raw_trajectories\n",
    "    info_key=get_stat_key(raw_trajectories,\"max\")\n",
    "        \n",
    "    info_dict={info_key:quantized_trajectories[info_key]}\n",
    "    \n",
    "    print(alg,info_dict)\n",
    "    \n",
    "    legend.append(f\"{alg} (%.2f)\"%quantized_trajectories[info_key][1])\n",
    "    figax=show_trajectories(info_dict, actions, 5, figsize=(16,4), max_allowed=1, fig_ax=figax,L=30,ms=8,color=colors[alg],marker=markers[alg],label=legend[-1])\n",
    "\n",
    "figax[1].legend(loc=(0.5,0.7),fontsize=8)\n",
    "\n",
    "plt.savefig(\"Legacy\\\\Figures\\\\Extraction2\\\\All_Trajectories.pdf\")\n",
    "\n",
    "plt.title(\"Best Trajectory\")\n",
    "\n",
    "#plt.yticks([1,4.5,8,11,18,21,28,31,38],[-1,0,1,0,1,0,1,0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3225a107",
   "metadata": {},
   "outputs": [],
   "source": [
    "def angleToRGB(theta,sc,w):\n",
    "    \n",
    "    #squish the greens\n",
    "    if theta<67.5:\n",
    "        theta=theta*0.8\n",
    "    elif theta<157.5:\n",
    "        theta=theta*2-72\n",
    "    else:\n",
    "        theta=theta*0.8+72\n",
    "    \n",
    "    \n",
    "    r=(theta/360+1.0/6)%1.0;\n",
    "    b=(theta/360+3.0/6)%1.0;\n",
    "    g=(theta/360+5.0/6)%1.0;\n",
    "    #colorwheel assignment multiplied by the scaler sc\n",
    "    r = (1 if r<1.0/3 else 3-6*r if r<1.0/2 else 0 if r<5.0/6 else 6*r-5)*sc+w;\n",
    "    g = (1 if g<1.0/3 else 3-6*g if g<1.0/2 else 0 if g<5.0/6 else 6*g-5)*sc+w;\n",
    "    b = (1 if b<1.0/3 else 3-6*b if b<1.0/2 else 0 if b<5.0/6 else 6*b-5)*sc+w;\n",
    "    \n",
    "    r=min(r,1)\n",
    "    g=min(g,1)\n",
    "    b=min(b,1)\n",
    "\n",
    "    return [r,g,b]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169382b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_trajectories3D(trajectories:dict,actions,bins_per_action,figsize=(7,3),alpha_map=lambda x:x**2,max_allowed=1e6):\n",
    "\n",
    "    \"\"\"\n",
    "    Plots a dictionary of hashed trajectories with transparency based off of the alpha map\n",
    "    \n",
    "    Args:\n",
    "    - trajectories (dict): Dictionary where keys are the trajectories and values are weights \n",
    "            (ex: keys are number trajectory counts, or reward achieved with the trajectory)\n",
    "    - actions (list of str): List of the names of each action\n",
    "    - bins_per_action (int): The number of bins for each main action in the multidiscrete\n",
    "    - figsize (tuple): The size you want the figure to be\n",
    "    - alpha_map (function): A function that translates normalized values (divided by the max to fit in (-inf,1))\n",
    "            to alpha values\n",
    "    - max_allowed (float): The maximum number of trajectories which can be plotted\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    b = bins_per_action\n",
    "    #actions\n",
    "    to_z = lambda x: [int(i) for j,i in enumerate(x[::2])]\n",
    "    #sub-values\n",
    "    to_y = lambda x: [int(x[2*j+1])+1 for j,i in enumerate(x[::2])]\n",
    "    #steps\n",
    "    to_x = lambda x: [j for j,_ in enumerate(x[::2])]\n",
    "    \n",
    "    #order the dict based on frequency\n",
    "    sorted_hashes = sorted([a for a in trajectories],key=lambda x:trajectories[x],reverse=True)\n",
    "    sorted_amounts = [trajectories[x] for x in sorted_hashes]\n",
    "    \n",
    "    #scale the graph\n",
    "    L=max(1,len(sorted_hashes[0])//2+11.8)\n",
    "    \n",
    "    \n",
    "    fig = plt.figure(1,figsize=figsize, dpi=240, facecolor='w', edgecolor='k')\n",
    "    ax = plt.axes(projection='3d')\n",
    "\n",
    "    \n",
    "    ncol=len(actions)\n",
    "    \n",
    "    for j,act in enumerate(actions[::-1]):\n",
    "        color=angleToRGB(j/ncol*360,1,0)\n",
    "        j2=len(actions)-j-1\n",
    "        bar = ax.bar3d([0],[bins_per_action],[j2],[L],[0],[1],color=color,alpha=0.5)\n",
    "        bar._sort_zpos=-1\n",
    "        plt.plot([],[],color=color,label=actions[j2])\n",
    "        \n",
    "    for a,string in enumerate(sorted_hashes):\n",
    "        if a<max_allowed:\n",
    "            x = np.array(to_x(string))\n",
    "            y = np.array(to_y(string))\n",
    "            z = np.array(to_z(string))\n",
    "            ones=x*0+1\n",
    "            for i,_ in enumerate(x):\n",
    "                color=angleToRGB((ncol-z[i]-1)/ncol*360,1,0)\n",
    "                bar = ax.bar3d(x[i]+0.05,(bins_per_action-y)[i],z[i],ones[i]*0.9,y[i],ones[i],color=color)\n",
    "                bar._sort_zpos=i\n",
    "            l = ax.plot(x+0.5,bins_per_action-y*0,z+0.5,\"k.-\")\n",
    "\n",
    "        else:break\n",
    "            \n",
    "    ax.set_xlabel(\"Step\")\n",
    "    ax.set_zlabel(\"Action\")\n",
    "    ax.set_ylabel(\"Sub-Value\")\n",
    "    #ax.set_xlim(-3,L+3)\n",
    "    #ax.set_ylim(-2,len(actions)+2)\n",
    "    ax.set_zticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.legend(fontsize=4,loc=\"center left\")\n",
    "    return fig,ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa34776",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = show_trajectories3D(quantized_trajectories,actions,5,figsize=(7,4),alpha_map=lambda x:x,max_allowed=1)\n",
    "\n",
    "ax.azim = -85\n",
    "ax.dist = 10\n",
    "ax.elev = 5\n",
    "plt.savefig(\"Legacy\\\\Figures\\\\bar.pdf\",bbox_inches=\"tight\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c82149f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_trajectory(trajectories:dict,actions,bins_per_action,figsize=(7,3),alpha_map=lambda x:x**2,max_steps=1e6):\n",
    "\n",
    "    \"\"\"\n",
    "    Plots a dictionary of hashed trajectories with transparency based off of the alpha map\n",
    "    \n",
    "    Args:\n",
    "    - trajectories (dict): Dictionary where keys are the trajectories and values are weights \n",
    "            (ex: keys are number trajectory counts, or reward achieved with the trajectory)\n",
    "    - actions (list of str): List of the names of each action\n",
    "    - bins_per_action (int): The number of bins for each main action in the multidiscrete\n",
    "    - figsize (tuple): The size you want the figure to be\n",
    "    - alpha_map (function): A function that translates normalized values (divided by the max to fit in (-inf,1))\n",
    "            to alpha values\n",
    "    - max_allowed (float): The maximum number of trajectories which can be plotted\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    max_allowed=1\n",
    "\n",
    "    b = bins_per_action\n",
    "    #actions\n",
    "    to_z = lambda x: [int(i) for j,i in enumerate(x[::2])]\n",
    "    #sub-values\n",
    "    to_y = lambda x: [int(x[2*j+1]) for j,i in enumerate(x[::2])]\n",
    "    #steps\n",
    "    to_x = lambda x: [j+1 for j,_ in enumerate(x[::2])]\n",
    "    \n",
    "    #order the dict based on frequency\n",
    "    sorted_hashes = sorted([a for a in trajectories],key=lambda x:trajectories[x],reverse=True)\n",
    "    sorted_amounts = [trajectories[x] for x in sorted_hashes]    \n",
    "    \n",
    "    fig = plt.figure(1,figsize=figsize, dpi=240, facecolor='w', edgecolor='k')\n",
    "    ax = plt.axes()\n",
    "\n",
    "    ncol=len(actions)\n",
    "    \n",
    "    for j,act in enumerate(actions[::-1]):\n",
    "        color=angleToRGB(j/ncol*360,1,0)\n",
    "        j2=len(actions)-j-1\n",
    "        plt.plot([],[],color=color,label=f\"{j2}: {actions[j2]}\")\n",
    "        \n",
    "    for a,string in enumerate(sorted_hashes):\n",
    "        if a<max_allowed:\n",
    "            x = np.array(to_x(string))\n",
    "            y = np.array(to_y(string))\n",
    "            z = np.array(to_z(string))\n",
    "            ones=x*0+1\n",
    "            for i,_ in enumerate(x):\n",
    "                if i>max_steps:\n",
    "                    break\n",
    "                color=angleToRGB((ncol-z[i]-1)/ncol*360,1,0)\n",
    "                bar = ax.bar(x[i],y[i]+1,color=color)\n",
    "\n",
    "                ax.text(bar[0].xy[0]+2*bar[0].get_width()/x.shape[0],0.2,str(z[i]))\n",
    "\n",
    "        else:break\n",
    "            \n",
    "    ax.set_xlabel(\"Step\")\n",
    "    #ax.set_zlabel(\"Action\")\n",
    "    ax.set_ylabel(\"Action-Value\")\n",
    "    print(min(max_steps,len(sorted_hashes[0])//2))\n",
    "    ax.set_xlim(0.5,min(max_steps+1,len(sorted_hashes[0])//2)+0.5)\n",
    "    #ax.set_ylim(-2,len(actions)+2)\n",
    "    ax.set_xticks([])#([x[0],x[x.shape[0]//2],x[-1]])\n",
    "    ax.set_yticks([])\n",
    "    ax.legend(fontsize=4,loc=\"upper left\")\n",
    "    return fig,ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d19b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.size\"]=10.0\n",
    "for alg in [\"DQN\",\"A2C\",\"PPO\",\"PPO-XL\"]:\n",
    "    \n",
    "    quantized_trajectories = hashed_trajectories(folders[alg],N=7,N2=5)\n",
    "    \n",
    "    info_key=get_stat_key(quantized_trajectories,\"max\")\n",
    "        \n",
    "    info_dict={info_key:quantized_trajectories[info_key]}\n",
    "    \n",
    "    fig,ax = hist_trajectory(info_dict,actions,5,figsize=(4,2),alpha_map=lambda x:x,max_steps=29)\n",
    "    ax.set_ylim(0,6)\n",
    "    #plt.savefig(f\"Legacy\\\\Figures\\\\Extraction\\\\bar{alg}.pdf\",bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "        \n",
    "    #quantized_trajectories=relabel_trajectories(quantized_trajectories,{\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"},\"8\",\"7\",5,default_wait=\"0\",dependencies=dependencies,use_return=True)\n",
    "    \n",
    "    sizes=np.array(sorted([quantized_trajectories[a] for a in quantized_trajectories]))\n",
    "    ratio=sizes.max()/np.sum(sizes[-100:])*4\n",
    "    print(sizes.max())\n",
    "    map_=lambda x:np.clip(x*ratio,0,1)\n",
    "    \n",
    "    show_trajectories(quantized_trajectories,actions,5,figsize=(8,4),alpha_map=map_,L=15,use_return=False,color=colors[alg],marker=markers[alg],\n",
    "                     max_allowed=1e2)\n",
    "    plt.savefig(f\"Legacy\\\\Figures\\\\Extraction2\\\\Traj{alg}.pdf\",bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5fdb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = folders[\"PPO-XL\"][folders[\"PPO-XL\"].Done==True].Reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3fc336",
   "metadata": {},
   "outputs": [],
   "source": [
    "N=100\n",
    "x=np.ones(N)\n",
    "n=15\n",
    "x[0:n]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86231f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.var(x)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce0793d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(x)+np.var(x)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c9af38",
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.max(x)-np.min(x))/x.shape[0]*np.sqrt(n*(x.shape[0]-n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb18ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(N,n,a=0,b=1):\n",
    "    return 1/N*(b-a)*(np.sqrt(n*(N-n))+(N-n))\n",
    "\n",
    "f(N,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fb7d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def g(N):\n",
    "    return max(f(N,a) for a in range(N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d95f267",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([g(N) for N in range(1,50)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81346efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(50)+50\n",
    "\n",
    "np.mean(x)\n",
    "np.var(x)**0.5+np.mean(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc788966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.system(\"python RLTrain.py algorithm=PPO environment=WurtzExtract-v1 n_envs=20 seed=1 steps=50000 dummy_vec=True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab18af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.system(\"python RLTrain.py algorithm=PPO environment=WurtzExtract-v1 n_envs=20 seed=1 steps=50000 dummy_vec=True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b90d0a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
